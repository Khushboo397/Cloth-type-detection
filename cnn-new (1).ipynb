{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, LeakyReLU\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "457620b25511ad8bb829e05851fb5df9cb306a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fashion-24l', 'fashionmnist', 'test-dataset', 'augmented-fashionmnist', 'fashion-noise-120000']\n"
     ]
    }
   ],
   "source": [
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "NUM_CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2018\n",
    "#Model\n",
    "NO_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "IS_LOCAL = False\n",
    "\n",
    "import os\n",
    "\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"../input/fashionmnist/\"\n",
    "else:\n",
    "    PATH=\"../input/\"\n",
    "print(os.listdir(PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120269, 784)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "train_file = '../input/fashion-24l/fashion_newdata.csv'\n",
    "train_label = '../input/fashion-24l/fashion_newlabel.csv'\n",
    "test_file  = '../input/fashionmnist/fashion-mnist_test.csv'\n",
    "\n",
    "X = pd.read_csv(train_file,header=None)\n",
    "y = pd.read_csv(train_label, header = None)\n",
    "test_data = pd.read_csv(test_file)\n",
    "print(X.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d4d676e5238168ff19c9f796f636ccd668f0b699"
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def data_preprocessing(raw):\n",
    "    out_y = keras.utils.to_categorical(raw.label, NUM_CLASSES)\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:,1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "38b9500e8a23b94bbab2afa7f4d18cba22f1ca42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = data_preprocessing(test_data)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e18481eb83de7954e60fc4a3ff0d22ee0694c2b0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18241722c1b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = np.array(train_data)\n",
    "X = train_data[:,1:]\n",
    "y  = train_data[:,784]\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "81c0242a5bd1f319a74280d5403bd55ada6e30bf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120269, 1)\n",
      "(120269, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y = y.astype('int')\n",
    "y = keras.utils.to_categorical(y, NUM_CLASSES)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "bc416118c22d94100f6ea929b332a26a10174e4b"
   },
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ff0e3f1afe5f45e46f2b230afb19453bb67805a6"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "d04eee74fa124f33be48fe795a5b30767d50cd0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4b0e0895877fbdb87d74f75d063a3eeddd8583f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion MNIST train -  rows: 96215  columns: (784,)\n",
      "Fashion MNIST valid -  rows: 24054  columns: (784,)\n",
      "Fashion MNIST test -  rows: 10000  columns: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\n",
    "print(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])\n",
    "print(\"Fashion MNIST test -  rows:\",X_test.shape[0],\" columns:\", X_test.shape[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "577f4472c552ee64da0d1247a793f33c1eafc0a2"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-69ea2c470cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "x = X_train.reshape(96000, 28,28)\n",
    "def plot(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "578e8dc49a5690f908275bc2c053318e6db9fb5d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "7de36a4957809b6dcb281a38812261486ac71c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96215, 28, 28, 1)\n",
      "(24054, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_train = X_train.reshape(96215, 28,28 ,1)\n",
    "X_val = X_val.reshape(24054, 28, 28, 1)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "8c64d79d2186fb544bbd873bdad194e0506aeb39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential()\\n# Add convolution 2D\\nmodel.add(Conv2D(32, kernel_size=(3, 3),\\n                 activation='relu',\\n                 kernel_initializer='he_normal',\\n                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\\nmodel.add(MaxPooling2D((2, 2)))\\n# Add dropouts to the model\\nmodel.add(Dropout(0.25))\\nmodel.add(Conv2D(64, \\n                 kernel_size=(3, 3), \\n                 activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n# Add dropouts to the model\\nmodel.add(Dropout(0.25))\\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\\n# Add dropouts to the model\\nmodel.add(Dropout(0.4))\\nmodel.add(Flatten())\\nmodel.add(Dense(128, activation='relu'))\\n# Add dropouts to the model\\nmodel.add(Dropout(0.3))\\nmodel.add(Dense(NUM_CLASSES, activation='softmax'))\\n\\n\\nmodel.compile(loss=keras.losses.categorical_crossentropy,\\n              optimizer='adam',\\n              metrics=['accuracy'])\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "'''model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e5ad92f90c9f411feb6edd4fb1eb92668d352f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "# Add dropouts to the model\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "03507bed262cb211406d7c69cce7138e28e50207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 242,442\n",
      "Trainable params: 241,994\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "7b31ee7426855e96a29380de4dbb84e66164a162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96215 samples, validate on 24054 samples\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      " - 21s - loss: 0.9362 - acc: 0.6599 - val_loss: 0.6320 - val_acc: 0.7662\n",
      "Epoch 2/50\n",
      " - 16s - loss: 0.6977 - acc: 0.7435 - val_loss: 0.5509 - val_acc: 0.7960\n",
      "Epoch 3/50\n",
      " - 16s - loss: 0.6315 - acc: 0.7696 - val_loss: 0.5121 - val_acc: 0.8099\n",
      "Epoch 4/50\n",
      " - 17s - loss: 0.5973 - acc: 0.7814 - val_loss: 0.4957 - val_acc: 0.8161\n",
      "Epoch 5/50\n",
      " - 16s - loss: 0.5679 - acc: 0.7905 - val_loss: 0.4856 - val_acc: 0.8158\n",
      "Epoch 6/50\n",
      " - 16s - loss: 0.5521 - acc: 0.7962 - val_loss: 0.4682 - val_acc: 0.8217\n",
      "Epoch 7/50\n",
      " - 16s - loss: 0.5368 - acc: 0.8024 - val_loss: 0.4567 - val_acc: 0.8279\n",
      "Epoch 8/50\n",
      " - 16s - loss: 0.5278 - acc: 0.8072 - val_loss: 0.4474 - val_acc: 0.8326\n",
      "Epoch 9/50\n",
      " - 17s - loss: 0.5166 - acc: 0.8105 - val_loss: 0.4512 - val_acc: 0.8310\n",
      "Epoch 10/50\n",
      " - 17s - loss: 0.5044 - acc: 0.8140 - val_loss: 0.4626 - val_acc: 0.8243\n",
      "Epoch 11/50\n",
      " - 16s - loss: 0.4985 - acc: 0.8165 - val_loss: 0.4354 - val_acc: 0.8357\n",
      "Epoch 12/50\n",
      " - 17s - loss: 0.4923 - acc: 0.8176 - val_loss: 0.4383 - val_acc: 0.8378\n",
      "Epoch 13/50\n",
      " - 17s - loss: 0.4873 - acc: 0.8195 - val_loss: 0.4603 - val_acc: 0.8251\n",
      "Epoch 14/50\n",
      " - 17s - loss: 0.4801 - acc: 0.8216 - val_loss: 0.4485 - val_acc: 0.8299\n",
      "Epoch 15/50\n",
      " - 16s - loss: 0.4761 - acc: 0.8242 - val_loss: 0.4269 - val_acc: 0.8397\n",
      "Epoch 16/50\n",
      " - 16s - loss: 0.4727 - acc: 0.8237 - val_loss: 0.4255 - val_acc: 0.8398\n",
      "Epoch 17/50\n",
      " - 16s - loss: 0.4677 - acc: 0.8267 - val_loss: 0.4249 - val_acc: 0.8395\n",
      "Epoch 18/50\n",
      " - 17s - loss: 0.4633 - acc: 0.8275 - val_loss: 0.4261 - val_acc: 0.8411\n",
      "Epoch 19/50\n",
      " - 17s - loss: 0.4590 - acc: 0.8297 - val_loss: 0.4140 - val_acc: 0.8459\n",
      "Epoch 20/50\n",
      " - 16s - loss: 0.4551 - acc: 0.8327 - val_loss: 0.4122 - val_acc: 0.8440\n",
      "Epoch 21/50\n",
      " - 16s - loss: 0.4525 - acc: 0.8310 - val_loss: 0.4215 - val_acc: 0.8411\n",
      "Epoch 22/50\n",
      " - 16s - loss: 0.4479 - acc: 0.8327 - val_loss: 0.4216 - val_acc: 0.8419\n",
      "Epoch 23/50\n",
      " - 17s - loss: 0.4470 - acc: 0.8335 - val_loss: 0.4109 - val_acc: 0.8478\n",
      "Epoch 24/50\n",
      " - 17s - loss: 0.4431 - acc: 0.8352 - val_loss: 0.4203 - val_acc: 0.8416\n",
      "Epoch 25/50\n",
      " - 17s - loss: 0.4448 - acc: 0.8345 - val_loss: 0.4035 - val_acc: 0.8482\n",
      "Epoch 26/50\n",
      " - 17s - loss: 0.4370 - acc: 0.8379 - val_loss: 0.4017 - val_acc: 0.8497\n",
      "Epoch 27/50\n",
      " - 17s - loss: 0.4364 - acc: 0.8380 - val_loss: 0.4067 - val_acc: 0.8481\n",
      "Epoch 28/50\n",
      " - 18s - loss: 0.4340 - acc: 0.8377 - val_loss: 0.4048 - val_acc: 0.8495\n",
      "Epoch 29/50\n",
      " - 17s - loss: 0.4325 - acc: 0.8378 - val_loss: 0.4379 - val_acc: 0.8295\n",
      "Epoch 30/50\n",
      " - 17s - loss: 0.4308 - acc: 0.8405 - val_loss: 0.4270 - val_acc: 0.8377\n",
      "Epoch 31/50\n",
      " - 17s - loss: 0.4306 - acc: 0.8399 - val_loss: 0.3920 - val_acc: 0.8535\n",
      "Epoch 32/50\n",
      " - 17s - loss: 0.4276 - acc: 0.8409 - val_loss: 0.4004 - val_acc: 0.8518\n",
      "Epoch 33/50\n",
      " - 18s - loss: 0.4261 - acc: 0.8404 - val_loss: 0.3984 - val_acc: 0.8508\n",
      "Epoch 34/50\n",
      " - 17s - loss: 0.4217 - acc: 0.8426 - val_loss: 0.4098 - val_acc: 0.8461\n",
      "Epoch 35/50\n",
      " - 17s - loss: 0.4244 - acc: 0.8424 - val_loss: 0.3948 - val_acc: 0.8533\n",
      "Epoch 36/50\n",
      " - 17s - loss: 0.4181 - acc: 0.8446 - val_loss: 0.4182 - val_acc: 0.8413\n",
      "Epoch 37/50\n",
      " - 18s - loss: 0.4194 - acc: 0.8435 - val_loss: 0.3975 - val_acc: 0.8523\n",
      "Epoch 38/50\n",
      " - 18s - loss: 0.4156 - acc: 0.8446 - val_loss: 0.3977 - val_acc: 0.8503\n",
      "Epoch 39/50\n",
      " - 16s - loss: 0.4142 - acc: 0.8460 - val_loss: 0.3980 - val_acc: 0.8516\n",
      "Epoch 40/50\n",
      " - 16s - loss: 0.4135 - acc: 0.8457 - val_loss: 0.3903 - val_acc: 0.8522\n",
      "Epoch 41/50\n",
      " - 16s - loss: 0.4131 - acc: 0.8459 - val_loss: 0.3884 - val_acc: 0.8550\n",
      "Epoch 42/50\n",
      " - 17s - loss: 0.4109 - acc: 0.8458 - val_loss: 0.4040 - val_acc: 0.8515\n",
      "Epoch 43/50\n",
      " - 16s - loss: 0.4107 - acc: 0.8473 - val_loss: 0.3962 - val_acc: 0.8514\n",
      "Epoch 44/50\n",
      " - 16s - loss: 0.4081 - acc: 0.8489 - val_loss: 0.3868 - val_acc: 0.8561\n",
      "Epoch 45/50\n",
      " - 16s - loss: 0.4066 - acc: 0.8495 - val_loss: 0.3845 - val_acc: 0.8579\n",
      "Epoch 46/50\n",
      " - 16s - loss: 0.4052 - acc: 0.8475 - val_loss: 0.3902 - val_acc: 0.8566\n",
      "Epoch 47/50\n",
      " - 18s - loss: 0.4069 - acc: 0.8483 - val_loss: 0.3817 - val_acc: 0.8581\n",
      "Epoch 48/50\n",
      " - 17s - loss: 0.4050 - acc: 0.8484 - val_loss: 0.3807 - val_acc: 0.8584\n",
      "Epoch 49/50\n",
      " - 17s - loss: 0.4030 - acc: 0.8471 - val_loss: 0.4016 - val_acc: 0.8519\n",
      "Epoch 50/50\n",
      " - 17s - loss: 0.4046 - acc: 0.8490 - val_loss: 0.3944 - val_acc: 0.8545\n"
     ]
    }
   ],
   "source": [
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=50,\n",
    "                  verbose=2,\n",
    "                  validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('model_fashion_16may.h5')\n",
    "model.save_weights('weights_fashion_16may.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "0841ac6b3892719396c28eb67f2c92cdcb2ffdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.20785363458991052\n",
      "Test accuracy: 0.9229\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "0d7a3321210cb29dbc053cea9b3096c02ab67962"
   },
   "outputs": [],
   "source": [
    "#get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "#get the indices to be plotted\n",
    "y_true = test_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "6a3bfc0b24e0fed822adf1327abeb2551aee49b9"
   },
   "outputs": [],
   "source": [
    "p = predicted_classes[:10000]\n",
    "y = y_true[:10000]\n",
    "correct = np.nonzero(p==y)[0]\n",
    "incorrect = np.nonzero(p!=y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "f13c1e07ef9ba419cf05566d524dd4d8e6488c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predicted classes: 9229\n",
      "Incorrect predicted classes: 771\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct predicted classes:\",correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\",incorrect.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "93338b0a7a24a02cec44a179ba3479714635f072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100, 1)\n",
      "(100, 28, 28, 1)\n",
      "(100, 10)\n",
      "Test loss: 1.5478395234793425\n",
      "Test accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'predicted_classes = model.predict_classes(test_x)\\n#get the indices to be plotted\\ny_true = test_y\\np = predicted_classes[:10000]\\ny = y_true[:10000]\\ncorrect = np.nonzero(p==y)[0]\\nincorrect = np.nonzero(p!=y)[0]\\nprint(\"Correct predicted classes:\",correct.shape[0])\\nprint(\"Incorrect predicted classes:\",incorrect.shape[0])'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = pd.read_csv('../input/test-dataset/test_data.csv')\n",
    "test_y = pd.read_csv('../input/test-dataset/test_label.csv')\n",
    "test_x  = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "test_x = test_x.reshape(100,28,28,1)\n",
    "test_y =  keras.utils.to_categorical(test_y, NUM_CLASSES)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "score1 = model.evaluate(test_x,test_y, verbose=0)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])\n",
    "#get the predictions for the test data'''\n",
    "'''predicted_classes = model.predict_classes(test_x)\n",
    "#get the indices to be plotted\n",
    "y_true = test_y\n",
    "p = predicted_classes[:10000]\n",
    "y = y_true[:10000]\n",
    "correct = np.nonzero(p==y)[0]\n",
    "incorrect = np.nonzero(p!=y)[0]\n",
    "print(\"Correct predicted classes:\",correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\",incorrect.shape[0])'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
